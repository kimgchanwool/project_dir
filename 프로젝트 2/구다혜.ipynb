{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d54c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def detail_table(link):\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.maximize_window()\n",
    "\n",
    "\n",
    "    url = link\n",
    "    browser.get(url) \n",
    "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "    \n",
    "    prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        curr_height = browser.execute_script(\"return document.body.scrollHeight\")    \n",
    "        if curr_height == prev_height:    \n",
    "            break    \n",
    "        prev_height = curr_height\n",
    "\n",
    "    title = soup.find('h3', {'class' : 'tts_head'}).get_text()\n",
    "    reporter = soup.find('div', {'class' : 'journalistcard_summary_name'}).get_text()\n",
    "    date = soup.find('span', {'class' : 't11'}).get_text()\n",
    "    categori = soup.find('em', {'class' : 'guide_categorization_item'}).get_text()\n",
    "    comment_cnt = browser.find_element_by_css_selector('span.u_cbox_count').text # 전체 댓글\n",
    "    comment_cnt = browser.find_element_by_css_selector('span.u_cbox_info_txt').text # 현재 댓글\n",
    "    texts = soup.find('div', {'class' : '_article_body_contents'}).get_text()\n",
    "    \n",
    "    return(title, reporter, date, comment_cnt, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2b6902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title, reporter, date, comment_cnt, texts = detail_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69b8894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처치 곤란 아이스팩, 이렇게 재활용했더니 감동이네요\n",
      "서경숙\n",
      "2021.07.19. 오후 8:37\n",
      "203\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "주민들에게 수거 받아 70세대에게 반찬 나눔 봉사를 무사히 끝냈습니다【오마이뉴스의 모토는 '모든 시민은 기자다'입니다. 시민 개인의 일상을 소재로 한 '사는 이야기'도 뉴스로 싣고 있습니다. 당신의 살아가는 이야기가 오마이뉴스에 오면 뉴스가 됩니다. 당신의 이야기를 들려주세요.】생선이나 냉동식품 등을 배송받을 때 들어있는 아이스팩이 처치 곤란일 때가 많았다. 코로나가 있기 전에는 소풍이나 나들이 등을 많이 나가기 때문에 아이스팩을 보관해 두었다가 사용할 일들이 종종 있었다. 주민센터에서 아이스팩을 수거하면서 종량제봉투를 주기도 했지만, 생각만 할 뿐 실천은 못 하고 모았다가 버리는 경우가 더 많았다. 그런데 그 처치 곤란 아이스팩을 소중하게 느낀 계기가 있었다.군산의 한 복지관에서 최근 주민분들에게 냉동실에서 자리를 차지하고 있는 아이스팩을 갖다달라고 요청하는 일이 생겼다. 나운복지관은 군산 한마음 지역자활센터와 함께 7월부터 11월까지 '공감 밥상' 사랑의 반찬 나눔 봉사를 진행하고 있다. 70세대마다 가가호호 방문하여 반찬을 전달하는 일이다.              ▲ 70개의 1주 반찬 한 집 한 집 나갈 반찬들이 나란히 나란히.            ⓒ 서경숙   코로나19로 인한 사회적 취약계층 어르신이나 청소년들에게 돌봄의 공백을 채워주는 대응사업이다. 그런데 뜨거운 여름 날에 반찬을 나눠드리면서 혹시나 음식이 상하지는 않을까 걱정되는 마음에 남는 아이스팩을 주민들에게 요청한 것이다.                ▲ 주민이 모아준 아이스 팩 반찬 나눔을 하면서 반찬이 상할까 봐 아이스 팩과 함께~            ⓒ 서경숙   이 소식을 들은 주민분들중에는 아이스팩을 한 박스를 챙겨서 가져오는 분도 있었다. 마음은 있어도 귀찮다는 이유로 함께 동참하지 못하는 경우도 많은데, 이렇게라도 함께 하는 분들이 있어서 마음이 따뜻해진다. 주 1회 반찬 나눔과 한 달에 두 번 과일 나눔의 봉사는 한국서부발전(주) 후원으로 충남사회복지공동모금회가 지원해 주고 있다. 70세대를 선정하기 위해서 추천을 받았다. 추천의 기준은 코로나로 인해 더 어려워지는 세대, 방학 동안 돌봄을 받지 못하는 청소년들, 코로나 거리두기 실천으로 멀리 있는 가족들이 방문하기 어려워 홀로 외롭거나 영양 상태가 걱정되시는 분들, 코로나로 인해 경제가 어려워지는 가정을 찾아서 선정하였다.               ▲ 맛있는 반찬 맛있는 반찬을 전달합니다.            ⓒ 서경숙                 ▲ 2주에 한 번 과일 전달 영양을 보충하기 위해서 신선한 과일로 건강을 보충합니다.            ⓒ 서경숙   도움을 필요로 하는 많은 대상자를 추천해 주었지만 딱 70세대만을 선정하여 반찬 나눔을 전달해야 하기 때문에 코로나의 어려움을 가장 절실히 느끼는 세대를 선정할 수밖에 없는 어려움이 있었다. 마음은 추천하는 모든 분 다 해드리고 싶을 것이다. 담당 선생님은 좋은 업체를 선정하고 직접 찾아가서 반찬의 맛과 품질, 청결 등을 확인하고 과일 상태 등을 확인하는 여러 일을 일사천리로 진행하였다. 내가 맡은 대상자 중 한 명을 추천하여 '공감 밥상' 반찬 나눔이 전달되었다.전달하면서도 불안감은 있었다. 날이 너무 더운데 반찬이 바로 전달되지 않아서 상하지는 않나? 아니면 어르신들이 반찬이 입에 맞지 않는다고나 하지 않을까? 하는 여러 걱정이 앞섰다. 반찬 전달이 있고 오후 시간 전화가 왔다.\"서 선생님 덕분에 오늘 맛있는 반찬 받아서 점심을 맛있게 먹었어요. 고마워요. 남은 반찬은 냉장고에 잘 넣어놨어요.\" 사업을 제안하고 선정되고 진행한 선생님은 따로 있는데, 고마움의 인사는 내가 먼저 받은 것이다. 어르신의 감사 인사가 왔다는 것을 바로 전달하면서 나뿐 아니라 복지관 모든 직원이 흐믓해진다.               ▲ 신선한 과일 대상자의 영양보충 위해 신선한 과일을 전달합니다.            ⓒ 서경숙   우리는 반찬과 과일만 나눠주는 일로 끝나지 않을 것이다. 전달하면서 코로나19로 인한 돌봄 공백과 결식 우려 세대에 대한 정기적인 모니터링을 진행하면서 서로 소통하고 마음을 전달하고 닫힌 마음의 문을 열게 할 것이다. 마음을 전하는 일은 큰 일만 있는 것이 아니다. 함께 소통하고 모으면 큰 사랑을 실천할 수 있다.덧붙이는 글 | 기자의 개인 블로그 등에 올라갑니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(title, reporter, date, comment_cnt, texts, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(browser.page_source, 'lxml')\n",
    "rankingnews = soup.find_all('div', {'class' : 'rankingnews_box'})\n",
    "\n",
    "try:\n",
    "    want_thing = input('정치, 경제, 사회, 생활, 세계, IT 중에 보고싶은 카테고리를 입력하세요.(모든 카테고리를 희망한다면 \"모두\"를 입력하세요) : ')\n",
    "    what_press = input('어느 언론사의 기사들을 보시겠습니까. (모든 언론사를 원하신다면 \"모두\" 라고 입력하십시오)')\n",
    "    cnt = int(input('각 언론사에서 몇개의 기사들을 보시겠습니까. (1~5의 값을 입력해주세요)'))\n",
    "    \n",
    "    for ranking in rankingnews:\n",
    "        # 언론사\n",
    "        press = ranking.find('strong', {'class' : 'rankingnews_name'}).text\n",
    "        # 언론사 안에 뉴스 \n",
    "        ranks = ranking.find_all('li')\n",
    "        count = 0\n",
    "        \n",
    "        for rank in ranks:\n",
    "            \n",
    "            #  언론사가 입력된 input 안에 없거나 '모두' 가 아니라면 \n",
    "            if what_press not in press and what_press != '모두':\n",
    "                continue\n",
    "            count+=1\n",
    "            \n",
    "            #처음에 모두를 입력하면 \n",
    "            if count > cnt:\n",
    "                break;\n",
    "            link = rank.find('a' , {'class' : \"list_title nclicks('RBP.rnknws')\"})\n",
    "             \n",
    "            if link:\n",
    "                title = link.get_text()\n",
    "                link = 'https://news.naver.com'+link['href']            \n",
    "                ord_id = link.split('&')[3] + link.split('&')[4]\n",
    "            \n",
    "                print(f'link >>>> {link} : title >>>{title} :  id >>>> {id}')\n",
    "#         text_title = i.get_text()\n",
    "#         oid = i['href'].split('&')[-3].split('=')[1]\n",
    "#         aid = i['href'].split('&')[-2].split('=')[1]\n",
    "#         # id값\n",
    "#         id = oid+ aid\n",
    "\n",
    "                # 상세페이지로\n",
    "                url = link\n",
    "                browser.get(url)\n",
    "                # 상세 페이지 soup\n",
    "                soup2 = BeautifulSoup(browser.page_source, 'lxml')\n",
    "                \n",
    "                # 카테고리\n",
    "                categori = soup2.find('em' , {'class' : 'guide_categorization_item'})\n",
    "                \n",
    "                print(categori, want_thing)\n",
    "                \n",
    "                if categori and want_thing == categori.text:\n",
    "                    categori = categori.text\n",
    "                \n",
    "                elif want_thing == ('모두'):\n",
    "                    catrgori = categori.text\n",
    "                \n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                title = title.replace('\"', \"'\")\n",
    "\n",
    "#                 sql = \"\"\"insert into headlines (ord_id, title, press, categori, link)\n",
    "#                 values( %d, %s, %s, %s, %s);\n",
    "#                 \"\"\"\n",
    "#                 time.sleep(2)\n",
    "#                 cursor.execute(sql)\n",
    "\n",
    "                # 기자\n",
    "                reporter = soup2.find('div', {'class' : 'journalistcard_summary_name'})\n",
    "                if reporter:\n",
    "                    reporter = reporter.text\n",
    "                    \n",
    "                # 게시 날짜\n",
    "                date = soup2.find('span', {'class' : 't11'}).text\n",
    "                \n",
    "                #comment_cnt = browser.find_element_by_css_selector('span.u_cbox_info_txt')\n",
    "                #print(comment_cnt.get_attribute(''))\n",
    "                \n",
    "                # 기사본문\n",
    "                texts = soup2.find('div', {'id' : 'articleBodyContents'})\n",
    "\n",
    "                soup2.select('li > strong')\n",
    "                texts = texts.text # 기사 본문\n",
    "                keyword = keyword_search(texts)\n",
    "                print(ord_id, reporter, date, keyword)\n",
    "                \n",
    "                sql = f\"\"\"insert into detail_news values(\"{ord_id}\", \"{reporter}\", \"{date}\", '{keyword}');\"\"\"\n",
    "                cursor.execute(sql)\n",
    "                time.sleep(2)           \n",
    "            else:\n",
    "                continue;\n",
    "finally:\n",
    "    db.commit()\n",
    "    db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
